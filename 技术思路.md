# Podcast Intelligence - 轻量级实现方案

## 目标

复用开源项目，快速跑通"播客 -> 转录 -> 摘要"流程。

---

## 推荐方案：基于 podcast-transcriber

**项目地址**: https://github.com/wendy7756/podcast-transcriber

### 为什么选它

| 特性 | 说明 |
|------|------|
| 多平台支持 | Apple Podcasts、小宇宙、RSS、直接音频URL |
| 本地转录 | Faster-Whisper，无需GPU也能跑 |
| 有Web UI | 开箱即用，不用写前端 |
| 中文友好 | 有中文文档，支持中文播客 |
| 摘要功能 | GPT-4o 生成结构化摘要 |

---

## Phase 1: 快速启动 (直接用)

### 1.1 环境准备

```bash
# 克隆项目
git clone https://github.com/wendy7756/podcast-transcriber.git
cd podcast-transcriber

# 安装Node依赖
npm install

# 创建Python虚拟环境
python -m venv venv
venv\Scripts\activate  # Windows

# 安装Python依赖
pip install faster-whisper

# 配置环境变量
copy .env.example .env
# 编辑 .env，填入 OPENAI_API_KEY
```

### 1.2 启动服务

```bash
npm start
# 访问 http://localhost:3000
```

### 1.3 验证测试

- [ ] 输入一个RSS Feed URL测试
- [ ] 输入一个小宇宙链接测试
- [ ] 确认转录和摘要正常输出

---

## Phase 2: 定制改造

### 2.1 添加RSS批量处理

在 `server/` 目录下新建 `batch_processor.js`:

```javascript
// 批量处理RSS订阅
const feeds = [
  'https://lexfridman.com/feed/podcast/',
  'https://feeds.simplecast.com/Y8lFbOT4',  // Freakonomics
];

// 定时检查新集并处理
```

### 2.2 自定义摘要模板

修改 `server/services/openaiService.js` 中的prompt，输出格式改为:

```json
{
  "tldr": "一句话总结",
  "key_points": ["要点1", "要点2", "要点3"],
  "why_it_matters": "行业影响分析",
  "tags": ["标签1", "标签2"]
}
```

### 2.3 输出到本地文件

```javascript
// 保存结果到 output/YYYY-MM-DD/
const fs = require('fs');
const outputDir = `output/${new Date().toISOString().split('T')[0]}`;
fs.mkdirSync(outputDir, { recursive: true });
fs.writeFileSync(`${outputDir}/${episodeTitle}.md`, summary);
```

---

## 备选方案对比

### 方案A: jschulman/ai-podcast (纯Python脚本)

```bash
git clone https://github.com/jschulman/ai-podcast.git
cd ai-podcast
pip install -r requirements.txt

# 配置 podcasts.txt (填入Feed ID)
# 配置 prompt.txt (自定义摘要提示词)

python podcast_series.py
```

**优点**: 简单、纯脚本、邮件投递
**缺点**: 依赖Podcast Index API，无Web UI

### 方案B: 自己组合轻量级工具链

```
feedparser (RSS解析)
    |
    v
yt-dlp (音频下载)
    |
    v
faster-whisper (本地转录)
    |
    v
本地LLM / API (摘要生成)
```

最小代码示例:

```python
import feedparser
from faster_whisper import WhisperModel

# 1. 解析RSS
feed = feedparser.parse('https://lexfridman.com/feed/podcast/')
audio_url = feed.entries[0].enclosures[0].href

# 2. 下载音频 (用requests或yt-dlp)
import requests
audio = requests.get(audio_url)
with open('temp.mp3', 'wb') as f:
    f.write(audio.content)

# 3. 转录
model = WhisperModel("base", device="cpu")
segments, info = model.transcribe("temp.mp3")
transcript = " ".join([s.text for s in segments])

# 4. 调用LLM生成摘要 (参考 D:\zz\try.py)
```

---

## 技术栈选择

| 组件 | 推荐 | 备选 |
|------|------|------|
| RSS解析 | feedparser | podcast-transcriber内置 |
| 音频下载 | 内置/yt-dlp | requests直接下载 |
| 转录 | Faster-Whisper (本地) | Whisper API ($0.006/min) |
| 摘要 | 本地模型 (D:\zz\try.py) | GPT-4o / Claude API |
| 存储 | 本地文件/MongoDB | - |

---

## 执行清单

### 第一步：跑通 podcast-transcriber

- [ ] 克隆仓库并安装依赖
- [ ] 配置 .env (OPENAI_API_KEY)
- [ ] 启动并测试一个播客
- [ ] 确认转录和摘要质量

### 第二步：接入本地LLM

- [ ] 修改 openaiService.js，调用本地模型
- [ ] 参考 D:\zz\try.py 的调用方式
- [ ] 测试摘要质量

### 第三步：批量处理

- [ ] 添加RSS订阅列表配置
- [ ] 实现增量检查逻辑
- [ ] 添加定时任务 (node-cron)

### 第四步：投递输出

- [ ] 输出到本地Markdown文件
- [ ] (可选) 推送到Notion

---

## 成本估算

| 方案 | 转录成本 | 摘要成本 | 月总成本 |
|------|----------|----------|----------|
| 全本地 | $0 (Faster-Whisper) | $0 (本地LLM) | $0 |
| 混合 | $0 (本地) | ~$0.10/集 (API) | ~$9/月 |
| 全API | $32/月 (Whisper) | $9/月 | ~$41/月 |

**推荐全本地方案**，成本为零。

---

## 关键依赖

```txt
# Python
faster-whisper
feedparser
requests

# Node.js (podcast-transcriber)
express
node-fetch
```

---

## 参考链接

- podcast-transcriber: https://github.com/wendy7756/podcast-transcriber
- ai-podcast: https://github.com/jschulman/ai-podcast
- Faster-Whisper: https://github.com/SYSTRAN/faster-whisper
- feedparser文档: https://feedparser.readthedocs.io/
